{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from fastparquet import ParquetFile, write\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import timeit\n",
    "import time\n",
    "from os.path import join\n",
    "\n",
    "# dateformat = 'yyyy-mm-dd 00:00:00'\n",
    "def date_to_timestamp(date):\n",
    "    return datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "\n",
    "def construct_query(table,querycols,startdate,enddate):\n",
    "    qry = 'SELECT '\n",
    "    for pos,query in enumerate(querycols):\n",
    "        if pos > 0: #add comma\n",
    "            qry += ','\n",
    "        qry += query \n",
    "    qry += ' from {} where block_timestamp >={} and block_timestamp <={}'.format(table,startdate,enddate) \n",
    "    return qry\n",
    "    \n",
    "#DATABASE CONNECTION\n",
    "create_engine.max_overflow = -1\n",
    "def db_to_parquet(table,cols,startdate, enddate):\n",
    "    startdate = date_to_timestamp(startdate)\n",
    "    enddate = date_to_timestamp(enddate)\n",
    "    if startdate > enddate:\n",
    "        startdate = enddate\n",
    "        print('STARTDATE WAS GREATER THAN ENDDATE. ADJUSTED TO BE EQUAL')\n",
    "        \n",
    "        \n",
    "    engine = create_engine('mysql+mysqlconnector://admin1:password@:3306/aionv4')\n",
    "    # read FROM DATABASE\n",
    "    qry = construct_query(table,cols,startdate,enddate)\n",
    "    print(qry)\n",
    "    df = pd.read_sql_query(qry,engine)\n",
    "    filename = table+\".parquet\"\n",
    "    savepath =\"../data/\"+table+\".parquet\"\n",
    "    df.to_parquet(savepath, engine='pyarrow', compression='gzip')\n",
    "    #pq.write_table(pa.Table.from_pandas(df),join('../data',filename),compression='gzip')\n",
    "    \n",
    "\n",
    "\n",
    "# SETUP DATA RETRIEVAL\n",
    "startdate = '2018-06-01 00:00:00'\n",
    "enddate = '2018-10-23 00:00:00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT block_number,miner_address,block_timestamp,difficulty,block_time,transaction_list from block where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT block_number,miner_address,block_timestamp,difficulty,block_time,transaction_list from block where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT block_number,miner_address,block_timestamp,difficulty,block_time,transaction_list from block where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT block_number,miner_address,block_timestamp,difficulty,block_time,transaction_list from block where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT block_number,miner_address,block_timestamp,difficulty,block_time,transaction_list from block where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT block_number,miner_address,block_timestamp,difficulty,block_time,transaction_list from block where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT block_number,miner_address,block_timestamp,difficulty,block_time,transaction_list from block where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT block_number,miner_address,block_timestamp,difficulty,block_time,transaction_list from block where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "1min 2s ± 1.77 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# GET BLOCKS\n",
    "# transaction list : transactionhash,from, to,value, timestamp, blocknumber]\n",
    "block_cols = ['block_number','miner_address','block_timestamp',\n",
    "              'difficulty','block_time','transaction_list']\n",
    "%timeit db_to_parquet('block',block_cols,startdate,enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT transaction_hash,transaction_timestamp,to_addr,from_addr,value,nrg_consumed,block_timestamp from transaction where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT transaction_hash,transaction_timestamp,to_addr,from_addr,value,nrg_consumed,block_timestamp from transaction where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT transaction_hash,transaction_timestamp,to_addr,from_addr,value,nrg_consumed,block_timestamp from transaction where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT transaction_hash,transaction_timestamp,to_addr,from_addr,value,nrg_consumed,block_timestamp from transaction where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT transaction_hash,transaction_timestamp,to_addr,from_addr,value,nrg_consumed,block_timestamp from transaction where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT transaction_hash,transaction_timestamp,to_addr,from_addr,value,nrg_consumed,block_timestamp from transaction where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT transaction_hash,transaction_timestamp,to_addr,from_addr,value,nrg_consumed,block_timestamp from transaction where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "SELECT transaction_hash,transaction_timestamp,to_addr,from_addr,value,nrg_consumed,block_timestamp from transaction where block_timestamp >=1527825600.0 and block_timestamp <=1540267200.0\n",
      "27.1 s ± 80.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# GET TRANSACTIONS\n",
    "transaction_cols = ['transaction_hash','transaction_timestamp','to_addr','from_addr',\n",
    "                    'value','nrg_consumed','block_timestamp']\n",
    "%timeit db_to_parquet('transaction',transaction_cols,startdate,enddate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
