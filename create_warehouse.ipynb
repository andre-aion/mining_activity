{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark/spark-2.3.2-bin-hadoop2.7')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import DateType, StringType\n",
    "from pyspark.sql import *\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Poolminers\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "sc=SparkContext.getOrCreate(spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read transactions\n",
    "df_tx = spark.read.parquet('../data/transaction.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read blocks\n",
    "def explode_block(df,col):\n",
    "    # explode the list the first time\n",
    "    df = df.withColumn(col,explode(split(f.col(col),'\\],\\[') ))\n",
    "    # explode the\n",
    "    #tx_hash = udf(lambda x: x.replace([],''))\n",
    "    #df = df.withColumn('col',tx_hash(df[col]))\n",
    "    # extract the transaction_hash\n",
    "    df = df.withColumn(col,regexp_replace('transaction_list', '(\\[|\\]|\")', ''))\n",
    "    df = df.withColumn(col, df[col].substr(0, 64))\n",
    "    return df\n",
    "    \n",
    "df_block = spark.read.parquet('../data/block.parquet')\n",
    "df_block_1 = explode_block(df_block,'transaction_list')\n",
    "#display entire cell\n",
    "#df_block_1.select(f.col('transaction_list')).show(50,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice dataframe\n",
    "# dateformat = 'yyyy-mm-dd 00:00:00'\n",
    "def date_to_timestamp(date):\n",
    "    return datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "\n",
    "startdate = '2018-09-01 00:00:00'\n",
    "enddate = '2018-09-07 00:00:00'\n",
    "def truncate_dataframe(df,startdate,enddate):\n",
    "    startdate = date_to_timestamp(startdate)\n",
    "    enddate = date_to_timestamp(enddate)\n",
    "    if startdate > enddate:\n",
    "        startdate = enddate\n",
    "    df = df.filter((f.col('block_timestamp') >= startdate) & \n",
    "              (f.col('block_timestamp') <= enddate))\n",
    "    df = timestamp_to_date(df,'block_timestamp')\n",
    "    return df\n",
    "\n",
    "def timestamp_to_date(df,col):\n",
    "    return df.withColumn('block_timestamp', f.from_unixtime('block_timestamp').cast(DateType()))\n",
    " \n",
    "# truncate dataframes\n",
    "df_block_2 = truncate_dataframe(df_block_1,startdate, enddate).drop('__index_level_0__')\n",
    "df_tx_1 = truncate_dataframe(df_tx,startdate,enddate).drop('block_timestamp')\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join dataframes\n",
    "df_pool_warehouse = df_block_2.join(df_tx_1, df_block_2.transaction_list == \n",
    "                                    df_tx_1.transaction_hash,how='left').drop('transaction_list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE TO PARQUET\n",
    "df_pool_warehouse = df_pool_warehouse.drop('__index_level_0__')\n",
    "df_pool_warehouse.write.parquet(\"../data/pool_warehouse.parquet\",compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92521\n"
     ]
    }
   ],
   "source": [
    "print(df_pool_warehouse.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
