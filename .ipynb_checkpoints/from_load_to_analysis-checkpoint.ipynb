{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastparquet import ParquetFile, write\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import dask.dataframe as dd\n",
    "import holoviews as hv\n",
    "import datashader as ds\n",
    "import gc\n",
    "from os.path import join, dirname\n",
    "import pyarrow \n",
    "import pyarrow.parquet as pq\n",
    "# PLOT USING HOLOVIEWS DASK AND DATASHADER\n",
    "import hvplot.pandas\n",
    "import hvplot.dask\n",
    "import hvplot as hv\n",
    "from bokeh.models import HoverTool\n",
    "from pdb import set_trace\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import dateutil.relativedelta\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTILS \n",
    "import findspark\n",
    "findspark.init('/usr/local/spark/spark-2.3.2-bin-hadoop2.7')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import DateType, StringType, IntegerType\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Poolminers\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc=SparkContext.getOrCreate(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# EXPLODE THE TRANSACTION_LIST COLUMN IN AIONV4.BLOCK\n",
    "def explode_block(df1,col):\n",
    "    # explode the list the first time\n",
    "    df1 = df1.withColumn(col,explode(split(f.col(col),'\\],\\[') ))\n",
    "    # extract the transaction_hash\n",
    "    df1 = df1.withColumn(col,regexp_replace('transaction_list', '(\\[|\\]|\")', ''))\n",
    "    df1 = df1.withColumn(col, df1[col].substr(0, 64))\n",
    "    return df1\n",
    "\n",
    "# munge block dataframe\n",
    "def hex_to_int(x):\n",
    "    return int(x,16)\n",
    "\n",
    "def munge_block(df1):\n",
    "    df1 = explode_block(df1,'transaction_list')\n",
    "    udf_hex_to_int = udf(hex_to_int,IntegerType())\n",
    "    df1 = df1.withColumn('difficulty',udf_hex_to_int('difficulty'))\n",
    "    return df1\n",
    "\n",
    "\n",
    "# MAKE LIST OF TIER 1 MINERS\n",
    "def make_tier1_list(df,threshold_tx_paid_out=10,threshold_blocks_mined_per_day=2.5):\n",
    "    # find all miners in period and make list\n",
    "    miner_list = [i.miner_address for i in df.select('miner_address').distinct().collect()]\n",
    "    # Count transactions paid out per day: group transactions by date and miner\n",
    "    # tier 1 = percentage mined per day > threshold || transactions paid out > threshold per day# make unique list of tier 1\n",
    "    df_temp = df.groupby('from_addr','block_timestamp').agg({'to_addr':'count'})\n",
    "    df_temp = df_temp.dropna()\n",
    "    # find daily mean\n",
    "    df_temp = df_temp.groupby('from_addr').agg({'count(to_addr)':'mean'})\n",
    "    df_temp = df_temp.filter(df_temp['avg(count(to_addr))']>=threshold_tx_paid_out)\n",
    "    # make list of tier 1 using tx paid out\n",
    "    list_a = [i.from_addr for i in df_temp.select('from_addr').distinct().collect()]\n",
    "    # check against miner list to ensure that only miners are included\n",
    "    list_a = list(set(miner_list) & set(list_a))\n",
    "    df_temp.unpersist()\n",
    "    \n",
    "    # Get percentage blocks mined per day: group by miner address, day and count\n",
    "    df_temp = df.groupby('miner_address','block_timestamp')\\\n",
    "        .agg({'block_number':'count'})\\\n",
    "        .withColumn('percent',100*(col('count(block_number)')/\n",
    "                                   sum(col('count(block_number)')).over(Window.partitionBy())))\n",
    "    df_temp = df_temp.groupby('miner_address').agg({'percent':'mean'})\n",
    "    df_temp = df_temp.filter(df_temp['avg(percent)']>=threshold_blocks_mined_per_day)\n",
    "    list_b = [i.miner_address for i in df_temp.select('miner_address').distinct().collect()]\n",
    "    df_temp.unpersist()\n",
    "    print(list_a)\n",
    "    print(list_b)\n",
    "    #merge lists, drop duplicates\n",
    "    tier1_miner_list = list(set(list_a+list_b))\n",
    "    del list_a,list_b\n",
    "\n",
    "    #check this list again miner_address\n",
    "    gc.collect()\n",
    "    return tier1_miner_list\n",
    "\n",
    "# dateformat = 'yyyy-mm-dd 00:00:00'\n",
    "# CHANGE INDIVIDUAL DATE TO TIMESTAMP\n",
    "def date_to_timestamp(date):\n",
    "    return datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "\n",
    "# CREATE TIMESTAMP COLUMN IN DATETYPE FORMAT GIVEN A SPARK DATAFRAME\n",
    "def timestamp_to_date(df,col):\n",
    "    return df.withColumn('block_timestamp', f.from_unixtime('block_timestamp').cast(DateType()))\n",
    "\n",
    "# TRUNCATE SPARK DATAFRAME GIVEN STRING DATES\n",
    "# dateformat = 'yyyy-mm-dd 00:00:00'\n",
    "def truncate_dataframe(df1,startdate,enddate):\n",
    "    # get a month of data prior to startdate\n",
    "    \n",
    "    startdate = date_to_timestamp(startdate)# get a month of data prior to startdate\n",
    "    startdate1 = startdate - ( 30 * 24 * 60 * 60)\n",
    "    enddate = date_to_timestamp(enddate)\n",
    "    if startdate > enddate:\n",
    "        startdate = enddate\n",
    "    df1 = df1.filter((f.col('block_timestamp') >= startdate1) & \n",
    "              (f.col('block_timestamp') <= enddate))\n",
    "    df1 = timestamp_to_date(df1,'block_timestamp')\n",
    "    return df1\n",
    "\n",
    "# UDF FUNCTIONS TO INCLUDE EXTERNAL \n",
    "class MyUDFs:\n",
    "    #DICTIONARY WHEN MATCHING POOLNAME WITH MINER ADDRESS    \n",
    "    def populate(self):\n",
    "        self.df_poolinfo = pd.read_csv('../data/poolinfo.csv')\n",
    "        self.dict_poolinfo = dict(zip(self.df_poolinfo.address,self.df_poolinfo.poolname))\n",
    "        self.pool_keys = list(self.dict_poolinfo.keys())\n",
    "        \n",
    "    def get_poolname_label(self):\n",
    "        def ab(miner_address,pool_tier):\n",
    "            if miner_address in self.pool_keys:\n",
    "                return self.dict_poolinfo[miner_address]\n",
    "            else:\n",
    "                if pool_tier == 1:\n",
    "                    return miner_address[0:10]\n",
    "                else:\n",
    "                    return 'tier 2'\n",
    "        return udf(ab,StringType())\n",
    "    \n",
    "    def get_poolname_label_list(self,lst):\n",
    "        output = list()\n",
    "        for miner_address in lst:\n",
    "            if miner_address in self.pool_keys:\n",
    "                output.append(self.dict_poolinfo[miner_address])\n",
    "        \n",
    "        return output\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FROM DATABASE\n",
    "df_tx = spark.read.parquet('../data/transaction.parquet')  \n",
    "df_block = spark.read.parquet('../data/block.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make data warehouse for period (start_date, enddate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENTER INPUT DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = '2018-09-01 00:00:00'\n",
    "enddate = '2018-09-07 00:00:00'\n",
    "analysis_period = startdate[0:10]+' to '+enddate[0:10]+': '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# truncate dataframes\n",
    "df_block_1 = truncate_dataframe(df_block,startdate, enddate).drop('__index_level_0__')\n",
    "df_block_1 = munge_block(df_block_1)\n",
    "\n",
    "df_tx_1 = truncate_dataframe(df_tx,startdate,enddate).drop('block_timestamp')\n",
    "#\n",
    "df_tx_1 = df_tx_1.drop('__index_level_0__')\n",
    "df = df_block_1.join(df_tx_1, df_block_1.transaction_list == \n",
    "                                    df_tx_1.transaction_hash,how='left').drop('transaction_list')\n",
    "df_tx.unpersist()\n",
    "df_tx_1.unpersist()\n",
    "df_block.unpersist()\n",
    "df_block_1.unpersist()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify tier 1 addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a099688bb19051b38c846580600812d095f89cfff7abc17ab6c4af63e408f2f1', 'a0afea235b391cc31bf4a26d6bb5513639c718941a47418bd6d4cf4f957e84f9', 'a0e342ff441c781e46cc9047cc60d8d7dd389bc33cd9ca6a560942d99adc4abb', 'a0d1565b5b1056942421b2473d25cc2ad2e14d1ed358a908f9a2475fff26d616', 'a0ed62bc7f308fa712792515d840f3a086fe36d9959207a468e2ca70ec503b89', 'a08fbc834b450044e750b90b2a43fec15ba03fd0c20fd5a3463f9f394235db5d', 'a07a07e8965418ed2355ed5b062dd9ec29a099578d7330c206666abcb0b9aab9', 'a05801fb2de5b76568a9c13f86766ebe3e6c438272e9fc6f5fabfcbea93048bf', 'a01e968221584946dac1e6842bf985de7ff49c8b9913220ed793d64a150b2864', 'a07981da70ce919e1db5f051c3c386eb526e6ce8b9e2bfd56e3f3d754b0a17f3', 'a04c126f9d2eba02c926210189c7bccf7ad86105dbca1c4d910cf2b692ac7dd5', 'a04372c5aaab61f0bc79500ba49043918851ab37887792977eff06319e976108', 'a08091ab0325e384ac45e560d2f85e4b741363aa98881d52d54233a02b33fcaa', 'a0e5150f600d56372b434465b204baec77b8ea44a8a30c7eabaeb9fe5844dc88', 'a023fae1b60e6cd37a3e5ca11331549ba9e8029618fb635ed29ad377b9d911f8', 'a0c5da302ca0aa2d6ab5dc7cc7fe024f1b7f1902e7a8ebeb7ff0dd4b6da10a77', 'a088082e8a56dfa1b0e903ec194048fa97007831789e42ed277dae2c64e9d95e', 'a0152340d7150b354782753d6222430fd37e0c746bdb371b93fd79ac78887eec', 'a06cac75d9211abff36fe2cf9e7fc1741b076cea40324eb597b3957942be483f', 'a03eadbf7347f78fcd9abd9d43f9b1b46fb62d8609778f87137c582aefdbaf67', 'a0da4b9e22f576dc07d971da1e6405471dbd9ee8a6b8bffc5e70b8ab9a7f962f', 'a0a0f44f1b7a9dbf2e7a7b3622a497302d30d9944527f17c9ea5edd1d71d9400', 'a0a1e55cbbffc99d9dcaf56e5350847267471cd6d69d4dead14953e5e82d97bf', 'a0910a7dbb1f919df576e9aa333e1d79b0a5234aefd168b5b240254579f926ef', 'a06e78398580c0f37add71f2b8914bcef5be4938b05e024b96da75438d074ef0', 'a0c7d62218147416e6ca65b2e5db075ef1e82b882a96536dd96429db22a2e40f', 'a00983f07c11ee9160a64dd3ba3dc3d1f88332a2869f25725f56cbd0be32ef7a', 'a0f2daa8de60d0e911fb468492242d604e1e11ec6f142bfee15757408aff2902', 'a00cdd702771503652087af2dc104f70e09b888d60ba215f9beffa57d7e4512c']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "threshold_tx_paid_out = 10\n",
    "threshold_blocks_mined_per_day = 2.5 # Percentage\n",
    "tier1_miner_list = make_tier1_list(df,threshold_tx_paid_out,threshold_blocks_mined_per_day)\n",
    "# ADD A COLUMN CALLED POOL_TIER: 1 , 2\n",
    "pool_tier_udf = f.udf(lambda miner_address: 1 if \n",
    "                      miner_address in tier1_miner_list else 2, IntegerType())\n",
    "df = df.withColumn('pool_tier',pool_tier_udf(df.miner_address))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label pools in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "myUDF  = MyUDFs()\n",
    "myUDF.populate() \n",
    "df = df.withColumn('poolname',myUDF.get_poolname_label()(df[\"miner_address\"],df[\"pool_tier\"]))               \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis & plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar graphs of Tier blocks mined over period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_miners(df,startdate):\n",
    "    # only plot requested period\n",
    "    startdate = datetime.strptime(startdate, \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_temp = df.filter(f.col('block_timestamp')>= startdate)\n",
    "    \n",
    "    df_temp = df_temp.groupby('poolname').agg({'block_number':'count'})\\\n",
    "        .withColumn('percent',100*(col('count(block_number)')/\n",
    "                                   sum(col('count(block_number)')).over(Window.partitionBy())))\n",
    "    # convert small group to pandas for plotting\n",
    "    df_temp = df_temp.toPandas().sort_values(by=['percent'],ascending=False)\n",
    "    # Leave out the datashade option to get the tooltip to work\n",
    "    \n",
    "    bar = df_temp.hvplot.bar('poolname', ['count(block_number)'], rot=90,\n",
    "                             subplots=True, shared_axes=False,\n",
    "                             width=800,height=400,\n",
    "                             title=analysis_period +'Miners, blockcount')\n",
    "    bar_perc = df_temp.hvplot.bar('poolname', ['percent'], rot=90,\n",
    "                                  subplots=True, shared_axes=False,\n",
    "                                  width=800,height=400,\n",
    "                                  title=analysis_period +'Miners by %')\n",
    "\n",
    "    \n",
    "    hover = HoverTool(tooltips=[\n",
    "        (\"blocks mined\", \"$count(block_number)\"),\n",
    "        (\"percentage\", \"$percent\")\n",
    "    ])\n",
    "\n",
    "    #plot.options(tools=[hover])\n",
    "    # display plot\n",
    "    hv.show(bar)\n",
    "    hv.show(bar_perc)\n",
    "    del df_temp\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difficulty(df,startdate):\n",
    "    # only plot requested period\n",
    "    startdate = datetime.strptime(startdate, \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_temp = df.filter(f.col('block_timestamp')>= startdate)\n",
    "\n",
    "    df_temp = df_temp.select('block_timestamp','difficulty')\n",
    "    #convert from string to int\n",
    "    df_temp = df_temp.toPandas().sort_values(by=['block_timestamp'])\n",
    "    line = df_temp.hvplot.line(x='block_timestamp',y='difficulty',rot=90,\n",
    "                               width=800,height=400,\n",
    "                               title=analysis_period +'Difficulty')\n",
    "    hv.show(line)\n",
    "    del df_temp\n",
    "    gc.collect()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Activity Miners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_active_miners(df,startdate):\n",
    "    # only plot requested period\n",
    "    startdate = datetime.strptime(startdate, \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_temp = df.filter(f.col('block_timestamp')>= startdate)\n",
    "    df_temp = df_temp.groupby('poolname','block_timestamp').agg({'block_number':'count'})\n",
    "    df_temp = df_temp.toPandas().sort_values(by=['block_timestamp'])\n",
    "    lines = df_temp.hvplot.line(x='block_timestamp',y='count(block_number)',rot=90,\n",
    "                                by='poolname',width=800,height=600,\n",
    "                                title=analysis_period+'pools blocks mined daily')\n",
    "    hv.show(lines)\n",
    "    del df_temp\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a0afea235b391cc31bf4a26d6bb5513639c718941a47418bd6d4cf4f957e84f9', 'a0e342ff441c781e46cc9047cc60d8d7dd389bc33cd9ca6a560942d99adc4abb', 'a0d1565b5b1056942421b2473d25cc2ad2e14d1ed358a908f9a2475fff26d616', 'a0ed62bc7f308fa712792515d840f3a086fe36d9959207a468e2ca70ec503b89', 'a08fbc834b450044e750b90b2a43fec15ba03fd0c20fd5a3463f9f394235db5d', 'a07a07e8965418ed2355ed5b062dd9ec29a099578d7330c206666abcb0b9aab9', 'a05801fb2de5b76568a9c13f86766ebe3e6c438272e9fc6f5fabfcbea93048bf', 'a01e968221584946dac1e6842bf985de7ff49c8b9913220ed793d64a150b2864', 'a07981da70ce919e1db5f051c3c386eb526e6ce8b9e2bfd56e3f3d754b0a17f3', 'a04c126f9d2eba02c926210189c7bccf7ad86105dbca1c4d910cf2b692ac7dd5', 'a04372c5aaab61f0bc79500ba49043918851ab37887792977eff06319e976108', 'a08091ab0325e384ac45e560d2f85e4b741363aa98881d52d54233a02b33fcaa', 'a0e5150f600d56372b434465b204baec77b8ea44a8a30c7eabaeb9fe5844dc88', 'a023fae1b60e6cd37a3e5ca11331549ba9e8029618fb635ed29ad377b9d911f8', 'a0c5da302ca0aa2d6ab5dc7cc7fe024f1b7f1902e7a8ebeb7ff0dd4b6da10a77', 'a06cac75d9211abff36fe2cf9e7fc1741b076cea40324eb597b3957942be483f', 'a03eadbf7347f78fcd9abd9d43f9b1b46fb62d8609778f87137c582aefdbaf67', 'a0da4b9e22f576dc07d971da1e6405471dbd9ee8a6b8bffc5e70b8ab9a7f962f', 'a0a0f44f1b7a9dbf2e7a7b3622a497302d30d9944527f17c9ea5edd1d71d9400', 'a0a1e55cbbffc99d9dcaf56e5350847267471cd6d69d4dead14953e5e82d97bf', 'a0910a7dbb1f919df576e9aa333e1d79b0a5234aefd168b5b240254579f926ef', 'a00cdd702771503652087af2dc104f70e09b888d60ba215f9beffa57d7e4512c', 'a06e78398580c0f37add71f2b8914bcef5be4938b05e024b96da75438d074ef0', 'a0c7d62218147416e6ca65b2e5db075ef1e82b882a96536dd96429db22a2e40f', 'a00983f07c11ee9160a64dd3ba3dc3d1f88332a2869f25725f56cbd0be32ef7a', 'a0f2daa8de60d0e911fb468492242d604e1e11ec6f142bfee15757408aff2902', 'a0152340d7150b354782753d6222430fd37e0c746bdb371b93fd79ac78887eec']\n",
      "[]\n",
      "--Return--\n",
      "> <ipython-input-259-08397754f3b5>(10)<module>()->None\n",
      "-> set_trace()\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-08397754f3b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# get tier 1 miner list for period under observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtier1_miner_list_period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtier1_miner_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#reuse the myUDF class defined in utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmyUDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyUDFs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bokeh_aion_analytics/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bokeh_aion_analytics/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_return\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;31m# The user issued a 'next' or 'until' command.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoplineno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# filter data from previous month, excluding timespan under observation\n",
    "startdate = datetime.strptime(startdate, \"%Y-%m-%d %H:%M:%S\")\n",
    "# get tier 1 miner list for previous period\n",
    "df_prev = df.filter(f.col('block_timestamp')<startdate)\n",
    "tier1_miner_list_prev = make_tier1_list(df_prev,threshold_tx_paid_out,\n",
    "                                         threshold_blocks_mined_per_day)\n",
    "\n",
    "# get tier 1 miner list for period under observation\n",
    "tier1_miner_list_period = tier1_miner_list\n",
    "#reuse the myUDF class defined in utils\n",
    "myUDF = MyUDFs()\n",
    "myUDF.populate()\n",
    "\n",
    "# POOLS RETAINED = INTERSECTION OF TWO T1 MINER LISTS\n",
    "retained = list(set(tier1_miner_list_prev) & set(tier1_miner_list_period))\n",
    "# POOLS DROPPED = IN LIST PREVIOUS BUT NOT IN THE NEW LIST\n",
    "dropped = np.setdiff1d(tier1_miner_list_prev,tier1_miner_list_period)\n",
    "# NEW POOLS = IN PERIOD UNDER OBSERVATION LIST BUT NOT IN PREVIOUS  MONTH LIST\n",
    "new = np.setdiff1d(tier1_miner_list_period,tier1_miner_list_prev)\n",
    "\n",
    "print(\"T1 POOLS RETAINED: \".format(myUDF.get_poolname_label_list(retained)))\n",
    "print(\"T1 POOLS DROPPED: \".format(myUDF.get_poolname_label_list(dropped)))\n",
    "print(\"NEW T1 POOLS: \".format(myUDF.get_poolname_label_list(new)))\n",
    "print(\"\\n---------------------------------------------\")\n",
    "print(\"ALL MINERS RETAINED:\".format(retained))\n",
    "print(\"ALL MINERS DROPPED:\".format(dropped))\n",
    "print(\"ALL NEW MINERS:\".format())\n",
    "\n",
    "df_prev.unpersist()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISPLAY PLOTS/DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_miners(df,startdate)\n",
    "plot_difficulty(df,startdate)\n",
    "plot_active_miners(df,startdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "print('time elaped = {} mins'.format(total/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "100px",
    "left": "74px",
    "top": "111.133px",
    "width": "226px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
