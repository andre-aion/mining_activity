{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastparquet import ParquetFile, write\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import dask.dataframe as dd\n",
    "import holoviews as hv\n",
    "import datashader as ds\n",
    "import gc\n",
    "from os.path import join, dirname\n",
    "import pyarrow \n",
    "import pyarrow.parquet as pq\n",
    "# PLOT USING HOLOVIEWS DASK AND DATASHADER\n",
    "import hvplot.pandas\n",
    "import hvplot.dask\n",
    "import hvplot as hv\n",
    "from bokeh.models import HoverTool\n",
    "from pdb import set_trace\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import dateutil.relativedelta\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTILS \n",
    "import findspark\n",
    "findspark.init('/usr/local/spark/spark-2.3.2-bin-hadoop2.7')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import DateType, StringType, IntegerType\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Poolminers\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc=SparkContext.getOrCreate(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# EXPLODE THE TRANSACTION_LIST COLUMN IN AIONV4.BLOCK\n",
    "def explode_block(df1,col):\n",
    "    # explode the list the first time\n",
    "    df1 = df1.withColumn(col,explode(split(f.col(col),'\\],\\[') ))\n",
    "    # extract the transaction_hash\n",
    "    df1 = df1.withColumn(col,regexp_replace('transaction_list', '(\\[|\\]|\")', ''))\n",
    "    df1 = df1.withColumn(col, df1[col].substr(0, 64))\n",
    "    return df1\n",
    "\n",
    "# munge block dataframe\n",
    "def hex_to_int(x):\n",
    "    return int(x,16)\n",
    "\n",
    "def munge_block(df1):\n",
    "    df1 = explode_block(df1,'transaction_list')\n",
    "    udf_hex_to_int = udf(hex_to_int,IntegerType())\n",
    "    df1 = df1.withColumn('difficulty',udf_hex_to_int('difficulty'))\n",
    "    return df1\n",
    "\n",
    "def value_hex_to_int(x):\n",
    "    output = 0\n",
    "    try:\n",
    "        output = int(str(x),16)\n",
    "        output = output if output >= 0 else -output\n",
    "    except:\n",
    "        output = 0\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "# MAKE LIST OF ALL MINERS\n",
    "def make_miner_list(df1):\n",
    "    df_temp = df1.groupby('to_addr').agg({'from_addr':'count'})\n",
    "    df_temp = df_temp.dropna()\n",
    "    column = 'to_addr'\n",
    "    miner_list_1 = df_temp.select(f.collect_set(column).alias(column)).first()[column]\n",
    "    df_temp.unpersist()\n",
    "    df_temp = df1.groupBy('miner_address').agg({'block_number':'count'})\n",
    "    d_temp = df_temp.dropna()\n",
    "    column = 'miner_address'\n",
    "    miner_list_0 = df_temp.select(f.collect_set(column).alias(column)).first()[column]\n",
    "    df_temp.unpersist()\n",
    "    return list(set(miner_list_1 + miner_list_0))\n",
    "\n",
    "# MAKE LIST OF TIER 1 MINERS\n",
    "def make_tier1_list(df1,threshold_tx_paid_out=10,threshold_blocks_mined_per_day=1):\n",
    "    miner_list = make_miner_list(df1)\n",
    "    # Count transactions paid out per day: group transactions by date and miner\n",
    "    # tier 1 = percentage mined per day > threshold || transactions paid out > threshold per day# make unique list of tier 1\n",
    "    df_temp = df1.groupBy('from_addr','block_timestamp').agg({'to_addr':'count'})\n",
    "    df_temp = df_temp.dropna()\n",
    "    # find daily mean\n",
    "    df_temp = df_temp.groupBy('from_addr').agg({'count(to_addr)':'mean'})\n",
    "    df_temp = df_temp.filter(df_temp['avg(count(to_addr))']>=threshold_tx_paid_out)\n",
    "    # make list of tier 1 using tx paid out\n",
    "    column = 'from_addr'\n",
    "    list_a = df_temp.select(f.collect_set(column).alias(column)).first()[column]\n",
    "    # check against miner list to ensure that only miners are included\n",
    "    list_a = list(set(miner_list) & set(list_a))\n",
    "    df_temp.unpersist()\n",
    "    \n",
    "    # Get percentage blocks mined per day: group by miner address, day and count\n",
    "    df_temp = df.groupBy('miner_address','block_timestamp')\\\n",
    "        .agg({'block_number':'count'})\\\n",
    "        .withColumn('percent',100*(col('count(block_number)')/\n",
    "                                   sum(col('count(block_number)')).over(Window.partitionBy())))\n",
    "    df_temp = df_temp.groupBy('miner_address').agg({'percent':'mean'})\n",
    "    df_temp = df_temp.filter(df_temp['avg(percent)']>=threshold_blocks_mined_per_day)\n",
    "    column = 'miner_address'\n",
    "    list_b = df_temp.select(f.collect_set(column).alias(column)).first()[column]\n",
    "    df_temp.unpersist()\n",
    "    #print(list_a)\n",
    "    print('Tier 1 miners from blocks mined daily > {}%: {}'.format(threshold_blocks_mined_per_day,\n",
    "                                                           list_b))\n",
    "    #merge lists, drop duplicates\n",
    "    tier1_miner_list = list(set(list_a+list_b))\n",
    "    del list_a,list_b\n",
    "\n",
    "    #check this list again miner_address\n",
    "    gc.collect()\n",
    "    return tier1_miner_list\n",
    "\n",
    "def make_tier2_list(df1,tier1_miner_list, threshold_tier2_pay_in):\n",
    "    # filter dataframe to retain only tx payouts from tier1 miner list\n",
    "    df1=df1.filter(df1.from_addr.isin(tier1_miner_list))\n",
    "    # filter dataframe to retain T2 for at least x payouts received per month\n",
    "    df_temp = df1.groupBy('to_addr','block_timestamp').agg({'to_addr':'count'})\n",
    "    df_temp = df_temp.dropna()\n",
    "    df_temp = df_temp.groupBy('to_addr').agg({'count(to_addr)':'mean'})    \n",
    "    df_temp = df_temp.filter(df_temp['avg(count(to_addr))']>=threshold_tier2_pay_in)\n",
    "    # tier 2 are the recipients from tier 1\n",
    "    column = 'to_addr'\n",
    "    tier2_miner_list = df_temp.select(f.collect_set(column).alias(column)).first()[column]\n",
    "    \n",
    "    # find tier 2 by finding complement of tier 1 list\n",
    "    df1.unpersist()\n",
    "    df_temp.unpersist()\n",
    "    return tier2_miner_list\n",
    "\n",
    "\n",
    "# dateformat = 'yyyy-mm-dd 00:00:00'\n",
    "# CHANGE INDIVIDUAL DATE TO TIMESTAMP\n",
    "def date_to_timestamp(date):\n",
    "    return datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "\n",
    "# CREATE TIMESTAMP COLUMN IN DATETYPE FORMAT GIVEN A SPARK DATAFRAME\n",
    "def timestamp_to_date(df,col):\n",
    "    return df.withColumn('block_timestamp', f.from_unixtime('block_timestamp').cast(DateType()))\n",
    "\n",
    "# TRUNCATE SPARK DATAFRAME GIVEN STRING DATES\n",
    "# dateformat = 'yyyy-mm-dd 00:00:00'\n",
    "def truncate_dataframe(df1,startdate,enddate):\n",
    "    # get the timeframe underreview\n",
    "    \n",
    "    # get an equivalent timeframe of data prior to startdate\n",
    "    startdate = date_to_timestamp(startdate)# get a month of data prior to startdate\n",
    "    enddate = date_to_timestamp(enddate)\n",
    "    timeframe = enddate - startdate\n",
    "    startdate1 = startdate - timeframe\n",
    "    # default to 30 days prior\n",
    "    if startdate > enddate:\n",
    "        startdate = enddate\n",
    "        startdate1 = startdate - ( 30 * 24 * 60 * 60)\n",
    "        \n",
    "    df1 = df1.filter((f.col('block_timestamp') >= startdate1) & \n",
    "              (f.col('block_timestamp') <= enddate))\n",
    "    df1 = timestamp_to_date(df1,'block_timestamp')\n",
    "    return df1\n",
    "\n",
    "# UDF FUNCTIONS TO INCLUDE EXTERNAL \n",
    "class MyUDFs:\n",
    "    #DICTIONARY WHEN MATCHING POOLNAME WITH MINER ADDRESS    \n",
    "    def populate(self):\n",
    "        self.df_poolinfo = pd.read_csv('../data/poolinfo.csv')\n",
    "        self.dict_poolinfo = dict(zip(self.df_poolinfo.address,self.df_poolinfo.poolname))\n",
    "        self.pool_keys = list(self.dict_poolinfo.keys())\n",
    "        \n",
    "    def get_poolname_label(self):\n",
    "        def ab(miner_address,pool_tier):\n",
    "            if miner_address in self.pool_keys:\n",
    "                return self.dict_poolinfo[miner_address]\n",
    "            else:\n",
    "                if pool_tier == 1:\n",
    "                    return miner_address[0:10]\n",
    "                else:\n",
    "                    return 'tier 2'\n",
    "        return udf(ab,StringType())\n",
    "    \n",
    "    def get_poolname_label_list(self,lst):\n",
    "        output = list()\n",
    "        for miner_address in lst:\n",
    "            if miner_address in self.pool_keys:\n",
    "                output.append(self.dict_poolinfo[miner_address])\n",
    "            else:\n",
    "                output.append(miner_address[0:10])\n",
    "        \n",
    "        return output\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FROM DATABASE\n",
    "block_columns = ['block_timestamp','difficulty','transaction_hash',\n",
    "                      'miner_address','block_number']\n",
    "tx_columns = ['block_timestamp','from_addr','to_addr','value']\n",
    "df_tx = spark.read.parquet('../data/transaction.parquet').select('transaction_hash','block_timestamp','from_addr','to_addr','value')  \n",
    "df_block = spark.read.parquet('../data/block.parquet').select('block_timestamp','difficulty','transaction_list',\n",
    "                      'miner_address','block_number')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make data warehouse for period (start_date, enddate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENTER INPUT DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = '2018-10-01 00:00:00'\n",
    "enddate = '2018-11-01 00:00:00'\n",
    "analysis_period = startdate[0:10]+' to '+enddate[0:10]+': '\n",
    "\n",
    "# for calculating retentions grab data from equally long period the month before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# truncate dataframes\n",
    "df_block_1 = truncate_dataframe(df_block,startdate, enddate).drop('__index_level_0__')\n",
    "df_block_1 = munge_block(df_block_1)\n",
    "\n",
    "df_tx_1 = truncate_dataframe(df_tx,startdate,enddate).drop('block_timestamp')\n",
    "#\n",
    "df_tx_1 = df_tx_1.drop('__index_level_0__')\n",
    "df = df_block_1.join(df_tx_1, df_block_1.transaction_list == \n",
    "                                    df_tx_1.transaction_hash,how='left').drop('transaction_list')\n",
    "\n",
    "df_tx.unpersist()\n",
    "df_tx_1.unpersist()\n",
    "df_block.unpersist()\n",
    "df_block_1.unpersist()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify tier 1 addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_tx_paid_out = 10\n",
    "threshold_blocks_mined_per_day = 0.5 # Percentage\n",
    "threshold_tier2_pay_in = 0.35 # minimum 10 tx per 28 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier 1 miners from blocks mined daily > 0.5%: ['a08091ab0325e384ac45e560d2f85e4b741363aa98881d52d54233a02b33fcaa']\n"
     ]
    }
   ],
   "source": [
    "tier1_miner_list = make_tier1_list(df,threshold_tx_paid_out,threshold_blocks_mined_per_day)\n",
    "# ADD A COLUMN CALLED POOL_TIER: 1 , 2\n",
    "pool_tier_udf = f.udf(lambda miner_address: 1 if \n",
    "                      miner_address in tier1_miner_list else 2, IntegerType())\n",
    "df = df.withColumn('pool_tier',pool_tier_udf(df.miner_address))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label pools in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "myUDF  = MyUDFs()\n",
    "myUDF.populate() \n",
    "df = df.withColumn('poolname',myUDF.get_poolname_label()(df[\"miner_address\"],df[\"pool_tier\"]))               \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis & plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining addresses and rewards, tier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier 1 miners from blocks mined daily > 0.5%: ['a08091ab0325e384ac45e560d2f85e4b741363aa98881d52d54233a02b33fcaa']\n",
      "2018-10-01 to 2018-11-01: : Daily rewards received by Tier 2 miners--4239192123873\n",
      "csv written\n",
      "time elapsed up til tier 2 mining rewards= 2.3896862943967183 mins\n"
     ]
    }
   ],
   "source": [
    "def plot_awards_tier2(df,startdate,enddate):\n",
    "    startdate = datetime.strptime(startdate, \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_curr = df.filter(col('block_timestamp')>=startdate)\n",
    "    # get the values for tier 2 miners\n",
    "    tier1_miner_list = make_tier1_list(df_curr,threshold_tx_paid_out,threshold_blocks_mined_per_day)\n",
    "    tier2_miner_list = make_tier2_list(df_curr,tier1_miner_list, threshold_tier2_pay_in)\n",
    "    # filter the dataframe for tier 2 miner\n",
    "    df_curr = df_curr.filter(df_curr.to_addr.isin(tier2_miner_list))\n",
    "    \n",
    "    # convert hex to int\n",
    "    udf_hex_to_int = udf(value_hex_to_int,IntegerType())\n",
    "    df_curr = df_curr.withColumn('value',udf_hex_to_int('value'))\n",
    "    \n",
    "    df_curr = df_curr.groupby('to_addr','block_timestamp').agg({'value':'sum'})\n",
    "    df_curr = df_curr.dropna()\n",
    "    # truncate address string\n",
    "    df_curr = df_curr.withColumn('to_addr_bar',df_curr['to_addr'].substr(0,10))\n",
    "\n",
    "    # convert small group to pandas for plotting\n",
    "    df_curr1 = df_curr.toPandas()\n",
    "    df_curr1 = df_curr1.rename(index=str,columns={'sum(value)':'rewards_received'})\n",
    "    df_curr1.sort_values(by=['rewards_received'],ascending=False,inplace=True)\n",
    "    # Leave out the datashade option to get the tooltip to work\n",
    "    '''\n",
    "    bar = df_curr1.hvplot.bar('to_addr_bar', ['rewards_received'], rot=90,\n",
    "                             width=7000,height=700,\n",
    "                             title=analysis_period +'Tier 2- Miners, value')\n",
    "    hv.show(bar)\n",
    "    '''\n",
    "    #table = df_curr1.hvplot.table(columns=['to_addr','block_timestamp', 'rewards_received'])\n",
    "    print('{}: Daily rewards received by Tier 2 miners-{}'\n",
    "          .format(analysis_period, df_curr1['rewards_received'].sum()))\n",
    "   \n",
    "    #hv.show(table)\n",
    "    df_curr1.to_csv('../data/'+analysis_period+':tier2_mining_rewards.csv'\n",
    "                   )\n",
    "    print('csv written')\n",
    "    del df_curr1\n",
    "    df_curr.unpersist()\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "plot_awards_tier2(df,startdate,enddate)\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "print('time elapsed up til tier 2 mining rewards= {} mins'.format(total/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar graphs of Tier blocks mined over period, poolname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_miners(df,startdate):\n",
    "    # only plot requested period\n",
    "    startdate = datetime.strptime(startdate, \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_temp = df.filter(f.col('block_timestamp')>= startdate)\n",
    "    \n",
    "    df_temp = df_temp.groupby('poolname').agg({'block_number':'count'})\\\n",
    "        .withColumn('percent',100*(col('count(block_number)')/\n",
    "                                   sum(col('count(block_number)')).over(Window.partitionBy())))\n",
    "    # convert small group to pandas for plotting\n",
    "    df_temp = df_temp.toPandas().sort_values(by=['block_timestamp','percent'],ascending=False)\n",
    "    # Leave out the datashade option to get the tooltip to work\n",
    "    \n",
    "    bar = df_temp.hvplot.bar('poolname', ['count(block_number)'], rot=90,\n",
    "                             subplots=True, shared_axes=False,\n",
    "                             width=800,height=400,\n",
    "                             title=analysis_period +'Miners, blockcount')\n",
    "    bar_perc = df_temp.hvplot.bar('poolname', ['percent'], rot=90,\n",
    "                                  subplots=True, shared_axes=False,\n",
    "                                  width=800,height=400,\n",
    "                                  title=analysis_period +'Miners by %')\n",
    "\n",
    "    \n",
    "    hover = HoverTool(tooltips=[\n",
    "        (\"blocks mined\", \"$count(block_number)\"),\n",
    "        (\"percentage\", \"$percent\")\n",
    "    ])\n",
    "\n",
    "    #plot.options(tools=[hover])\n",
    "    # display plot\n",
    "    hv.show(bar)\n",
    "    hv.show(bar_perc)\n",
    "    del df_temp\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#startdate = '2018-10-01 00:00:00'\n",
    "#enddate = '2018-10-14 00:00:00'\n",
    "analysis_period = startdate[0:10]+' to '+enddate[0:10]+': '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difficulty(df,startdate):\n",
    "    # only plot requested period\n",
    "    startdate = datetime.strptime(startdate, \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_temp = df.filter(f.col('block_timestamp')>= startdate)\n",
    "\n",
    "    df_temp = df_temp.select('block_timestamp','difficulty')\n",
    "    #convert from string to int\n",
    "    df_temp = df_temp.toPandas().sort_values(by=['block_timestamp'])\n",
    "    line = df_temp.hvplot.line(x='block_timestamp',y='difficulty',rot=90,\n",
    "                               width=800,height=400,\n",
    "                               title=analysis_period +'Difficulty')\n",
    "    hv.show(line)\n",
    "    del df_temp\n",
    "    gc.collect()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Activity Miners - blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_active_miners(df,startdate):\n",
    "    # only plot requested period\n",
    "    startdate = datetime.strptime(startdate, \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_temp = df.filter(f.col('block_timestamp')>= startdate)\n",
    "    df_temp = df_temp.groupby('poolname','block_timestamp').agg({'block_number':'count'})\n",
    "    df_temp = df_temp.toPandas().sort_values(by=['block_timestamp'])\n",
    "    lines = df_temp.hvplot.line(x='block_timestamp',y='count(block_number)',rot=90,\n",
    "                                by='poolname',width=800,height=600,\n",
    "                                title=analysis_period+'pools blocks mined daily')\n",
    "    hv.show(lines)\n",
    "    del df_temp\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_retention(df,startdate):\n",
    "    # filter data from previous month, excluding timespan under observation\n",
    "    startdate = datetime.strptime(startdate, \"%Y-%m-%d %H:%M:%S\")\n",
    "    # get tier 1 miner list for previous period\n",
    "    df_prev = df.filter(f.col('block_timestamp')<startdate)\n",
    "    tier1_miner_list_prev = make_tier1_list(df_prev,threshold_tx_paid_out,\n",
    "                                             threshold_blocks_mined_per_day)\n",
    "    miner_list_prev = make_miner_list(df_prev)\n",
    "    # get tier 1 miner list for period under observation\n",
    "    tier1_miner_list_period = tier1_miner_list\n",
    "    #reuse the myUDF class defined in utils\n",
    "    myUDF = MyUDFs()\n",
    "    myUDF.populate()\n",
    "    df_prev.unpersist()\n",
    "\n",
    "    df_period = df.filter(f.col('block_timestamp')>=startdate)\n",
    "    miner_list_period = make_miner_list(df_period)\n",
    "    # POOLS RETAINED = INTERSECTION OF TWO T1 MINER LISTS\n",
    "    retained = list(set(tier1_miner_list_prev) & set(tier1_miner_list_period))\n",
    "    retained_all = len(list(set(miner_list_prev) & set(miner_list_period)))\n",
    "    # POOLS DROPPED = IN LIST PREVIOUS BUT NOT IN THE NEW LIST\n",
    "    dropped = np.setdiff1d(tier1_miner_list_prev,tier1_miner_list_period)\n",
    "    dropped_all = len(np.setdiff1d(miner_list_prev,miner_list_period))\n",
    "    # NEW POOLS = IN PERIOD UNDER OBSERVATION LIST BUT NOT IN PREVIOUS  MONTH LIST\n",
    "    new = np.setdiff1d(tier1_miner_list_period,tier1_miner_list_prev)\n",
    "    new_all = len(np.setdiff1d(miner_list_period,miner_list_prev))\n",
    "    print(\"T1 POOLS RETAINED:{}\".format(myUDF.get_poolname_label_list(retained)))\n",
    "    print(\"T1 POOLS DROPPED:{}\".format(myUDF.get_poolname_label_list(dropped)))\n",
    "    print(\"NEW T1 POOLS:{}\".format(myUDF.get_poolname_label_list(new)))\n",
    "    print(\"\\n---------------------------------------------\")\n",
    "    print(\"ALL MINERS RETAINED:{}\".format(retained_all))\n",
    "    print(\"ALL MINERS DROPPED:{}\".format(dropped_all))\n",
    "    print(\"ALL NEW MINERS:{}\".format(new_all))\n",
    "    \n",
    "    df_period.unpersist()\n",
    "    gc.collect()\n",
    "pool_retention(df,startdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISPLAY PLOTS/DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_miners(df,startdate)\n",
    "plot_difficulty(df,startdate)\n",
    "plot_active_miners(df,startdate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "print('time elaped = {} mins'.format(total/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "100px",
    "left": "74px",
    "top": "111.133px",
    "width": "226px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
